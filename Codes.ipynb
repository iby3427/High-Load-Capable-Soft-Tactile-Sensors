{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a2S2j-bL0Wox",
        "TNMJNNFE2QZf",
        "hHx3UrLe4dkS",
        "JWF9C5R34ePy",
        "ufqvbYPt43Ag",
        "IwndKaMg43Ag",
        "c5fZwhDYtn1w",
        "QT7Ml1sjvMZE",
        "Hs4a-zyXwudB",
        "8Dml1GE5wyPM",
        "d6yesm7fxjSF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Making Section classification model"
      ],
      "metadata": {
        "id": "DqvLewvh1pj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Google drive and call the Dataset (Section classification)"
      ],
      "metadata": {
        "id": "a2S2j-bL0Wox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "class MyBaseDataset_for_sec_Cla(Dataset):\n",
        "  def __init__(self, data_input):\n",
        "    data_input = torch.tensor(data_input).float()\n",
        "    self.xyz_data = data_input[:,:12]\n",
        "    self.sec = data_input[:, [14]]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.xyz_data[index], self.sec[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.xyz_data.shape[0]\n",
        "\n",
        "data_for_sec = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/2023 Advanced/Sensor_data.xlsx', sheet_name=None)\n",
        "sheets_sec = list(data_for_sec.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "ygNRlCIm0c0V",
        "outputId": "be09926f-0a93-48b0-853f-f75da43ddc70"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-931e569ef069>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdata_for_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/2023 Advanced/Sensor_data.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0msheets_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_for_sec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         data = io.parse(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mDataFrame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mExcel\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \"\"\"\n\u001b[0;32m-> 1734\u001b[0;31m         return self._reader.parse(\n\u001b[0m\u001b[1;32m   1735\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mfile_rows_needed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_rows_needed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"close\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0;31m# pyxlsb opens two TemporaryFiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36mget_sheet_data\u001b[0;34m(self, sheet, convert_float, file_rows_needed)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mlast_row_with_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0mconverted_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_float\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mconverted_row\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconverted_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0;31m# trim trailing empty elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mlast_row_with_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0mconverted_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_float\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mconverted_row\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconverted_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0;31m# trim trailing empty elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m_convert_cell\u001b[0;34m(self, cell, convert_float)\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     def get_sheet_data(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/cell/read_only.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '81-Section Non-divided state Dataset (Section Classification)'"
      ],
      "metadata": {
        "id": "TNMJNNFE2QZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_Cla = data_for_sec[sheets_sec[2]]\n",
        "dataset_sec_Cla = MyBaseDataset_for_sec_Cla(sheet_sec_Cla.values)\n",
        "dataloader_sec_Cla = DataLoader(dataset=dataset_sec_Cla,batch_size=len(dataset_sec_Cla) , shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "for i, (inputs, sec) in enumerate(dataloader_sec_Cla):\n",
        "  pass\n",
        "\n",
        "inputs = inputs.numpy()\n",
        "sec = sec.numpy()\n",
        "\n",
        "\n",
        "B_train_Cla_81_ND, B_test_Cla_81_ND, sec_train_81_ND, sec_test_81_ND = train_test_split(inputs, sec, random_state=1)\n",
        "print(\"B_train: \", B_train_Cla_81_ND)\n",
        "print(\"sec: \", sec_train_81_ND)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ9ShGrl2c7-",
        "outputId": "50d887dc-fba3-4b6b-aef6-b815170abfd3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train:  [[  2.3668091   5.1880636 -60.332405  ... -39.67036   -44.42633\n",
            "   62.314404 ]\n",
            " [ -6.6331906  -6.8119364  96.667595  ... -34.67036   -38.42633\n",
            "  -75.68559  ]\n",
            " [  2.3668091   5.1880636 -60.332405  ... -32.67036   -40.42633\n",
            "  -58.685596 ]\n",
            " ...\n",
            " [ -0.6331908   1.1880637 -14.332406  ... -31.670362  -38.42633\n",
            "  -76.68559  ]\n",
            " [  1.3668091   2.1880636 -66.332405  ... -31.670362  -41.42633\n",
            "  -61.685596 ]\n",
            " [  3.3668091   4.1880636 -69.332405  ... -32.67036   -44.42633\n",
            "  -31.685595 ]]\n",
            "sec:  [[48.]\n",
            " [63.]\n",
            " [71.]\n",
            " ...\n",
            " [72.]\n",
            " [67.]\n",
            " [65.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '81-Section Loaded state Dataset (Section Classification)'"
      ],
      "metadata": {
        "id": "hHx3UrLe4dkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_Cla = data_for_sec[sheets_sec[0]]\n",
        "dataset_sec_Cla = MyBaseDataset_for_sec_Cla(sheet_sec_Cla.values)\n",
        "dataloader_sec_Cla = DataLoader(dataset=dataset_sec_Cla,batch_size=len(dataset_sec_Cla) , shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "for i, (inputs, sec) in enumerate(dataloader_sec_Cla):\n",
        "  pass\n",
        "\n",
        "inputs = inputs.numpy()\n",
        "sec = sec.numpy()\n",
        "\n",
        "\n",
        "B_train_Cla_81_L, B_test_Cla_81_L, sec_train_81_L, sec_test_81_L = train_test_split(inputs, sec, random_state=1)\n",
        "print(\"B_train: \", B_train_Cla_81_L)\n",
        "print(\"sec: \", sec_train_81_L)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0ee1c5-de06-4bc0-8f4f-a753b653becf",
        "id": "uQotwX6w4dkT"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train:  [[  0.36680916   1.1880637   -7.3324065  ... -35.67036    -40.42633\n",
            "  -31.685595  ]\n",
            " [  0.28050548  -1.5635498    1.3294873  ...   0.9069548    1.6788399\n",
            "   -5.6491437 ]\n",
            " [ -0.7194945    0.43645024   1.3294873  ...  -1.0930452   -0.32116014\n",
            "   -0.6491438 ]\n",
            " ...\n",
            " [ -6.6331906   -6.8119364  111.667595   ... -34.67036    -38.42633\n",
            "  -61.685596  ]\n",
            " [ -1.5460275   -0.37734982  10.535283   ...   1.9590049   -0.7524243\n",
            "  -12.263972  ]\n",
            " [  1.3668091    4.1880636  -46.332405   ... -32.67036    -40.42633\n",
            "  -35.685596  ]]\n",
            "sec:  [[24.]\n",
            " [81.]\n",
            " [ 0.]\n",
            " ...\n",
            " [27.]\n",
            " [78.]\n",
            " [51.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '81-Section Unloaded state Dataset (Section Classification)'"
      ],
      "metadata": {
        "id": "JWF9C5R34ePy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_Cla = data_for_sec[sheets_sec[1]]\n",
        "dataset_sec_Cla = MyBaseDataset_for_sec_Cla(sheet_sec_Cla.values)\n",
        "dataloader_sec_Cla = DataLoader(dataset=dataset_sec_Cla,batch_size=len(dataset_sec_Cla) , shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "for i, (inputs, sec) in enumerate(dataloader_sec_Cla):\n",
        "  pass\n",
        "\n",
        "inputs = inputs.numpy()\n",
        "sec = sec.numpy()\n",
        "\n",
        "\n",
        "B_train_Cla_81_UL, B_test_Cla_81_UL, sec_train_81_UL, sec_test_81_UL = train_test_split(inputs, sec, random_state=1)\n",
        "print(\"B_train: \", B_train_Cla_81_UL)\n",
        "print(\"sec: \", sec_train_81_UL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c452f853-8988-44f0-c676-ee5ed1baaba7",
        "id": "o67QwCS44ePy"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train:  [[  3.3668091    3.1880636  -39.332405   ... -32.67036    -38.42633\n",
            "  -68.68559   ]\n",
            " [  4.3668094    5.1880636  -68.332405   ... -34.67036    -42.42633\n",
            "  -23.685595  ]\n",
            " [  0.75058275   0.5882446    1.1367968  ...   1.917181     0.4168278\n",
            "   -1.9467003 ]\n",
            " ...\n",
            " [  1.3668091    4.1880636  -45.332405   ... -37.67036    -40.42633\n",
            "    6.314405  ]\n",
            " [  0.4539725    1.6226501  -11.464717   ...   0.95900494   1.2475756\n",
            "  -29.263973  ]\n",
            " [ 11.136959     5.8633785   65.86265    ...   0.75949955   1.5899355\n",
            "  -11.6148205 ]]\n",
            "sec:  [[59.]\n",
            " [52.]\n",
            " [ 1.]\n",
            " ...\n",
            " [47.]\n",
            " [79.]\n",
            " [80.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '9-Section Non-divided state Dataset (Section Classification)'"
      ],
      "metadata": {
        "id": "ufqvbYPt43Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_Cla = data_for_sec[sheets_sec[5]]\n",
        "dataset_sec_Cla = MyBaseDataset_for_sec_Cla(sheet_sec_Cla.values)\n",
        "dataloader_sec_Cla = DataLoader(dataset=dataset_sec_Cla,batch_size=len(dataset_sec_Cla) , shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "for i, (inputs, sec) in enumerate(dataloader_sec_Cla):\n",
        "  pass\n",
        "\n",
        "inputs = inputs.numpy()\n",
        "sec = sec.numpy()\n",
        "\n",
        "\n",
        "B_train_Cla_9_ND, B_test_Cla_9_ND, sec_train_9_ND, sec_test_9_ND = train_test_split(inputs, sec, random_state=1)\n",
        "print(\"B_train: \", B_train_Cla_9_ND)\n",
        "print(\"sec: \", sec_train_9_ND)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2984dc7d-0876-40a8-a30a-5a659a507422",
        "id": "2DyevZOm43Ag"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train:  [[-1.7461498e+00 -2.1006364e-02  1.6233389e+01 ... -1.0038992e+00\n",
            "  -1.1146252e+00  3.5002840e+00]\n",
            " [-3.7461498e+00 -6.0210066e+00  8.6233391e+01 ... -1.0038992e+00\n",
            "   8.8537478e-01  2.5002840e+00]\n",
            " [ 2.5385022e-01  9.7899365e-01 -7.6661146e-01 ... -1.0038992e+00\n",
            "   1.8853748e+00  5.0028384e-01]\n",
            " ...\n",
            " [ 2.7454535e-02  9.0658973e-04  1.7134614e+00 ... -7.9544818e-01\n",
            "   1.8698518e+00  2.0625511e-01]\n",
            " [ 1.9760938e+00 -2.2768957e+01  1.4856535e+02 ...  1.1830101e+00\n",
            "   8.4027290e-01 -7.5328064e-01]\n",
            " [-5.4530793e-01 -1.1110662e+00  1.8307078e-01 ... -1.8811239e+00\n",
            "   8.0819678e-01 -1.2678894e+00]]\n",
            "sec:  [[666.]\n",
            " [666.]\n",
            " [  0.]\n",
            " ...\n",
            " [999.]\n",
            " [999.]\n",
            " [  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '9-Section Loaded state Dataset (Section Classification)'"
      ],
      "metadata": {
        "id": "IwndKaMg43Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_Cla = data_for_sec[sheets_sec[3]]\n",
        "dataset_sec_Cla = MyBaseDataset_for_sec_Cla(sheet_sec_Cla.values)\n",
        "dataloader_sec_Cla = DataLoader(dataset=dataset_sec_Cla,batch_size=len(dataset_sec_Cla) , shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "for i, (inputs, sec) in enumerate(dataloader_sec_Cla):\n",
        "  pass\n",
        "\n",
        "inputs = inputs.numpy()\n",
        "sec = sec.numpy()\n",
        "\n",
        "\n",
        "B_train_Cla_9_L, B_test_Cla_9_L, sec_train_9_L, sec_test_9_L = train_test_split(inputs, sec, random_state=1)\n",
        "print(\"B_train: \", B_train_Cla_9_L)\n",
        "print(\"sec: \", sec_train_9_L)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e14f89-9e1f-4132-9c56-b456d57f32ec",
        "id": "ydIQ1ja843Ah"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train:  [[ 1.2574178e-01  9.3437207e-01 -1.0174589e+00 ... -8.1967074e-01\n",
            "   8.2012278e-01 -2.0581493e+00]\n",
            " [ 2.7454535e-02  9.0658973e-04 -4.2865386e+00 ...  1.2045518e+00\n",
            "   8.6985183e-01  9.2062550e+00]\n",
            " [ 2.5385022e-01 -2.1006364e-02  2.3338854e-01 ... -1.0038992e+00\n",
            "   8.8537478e-01  5.0028384e-01]\n",
            " ...\n",
            " [ 2.6537970e-01 -9.3219274e-01  1.6111872e+01 ...  1.1763110e+00\n",
            "  -1.1500872e+00  1.1305597e+00]\n",
            " [ 1.9760938e+00 -2.1768957e+01  1.4856535e+02 ...  1.1830101e+00\n",
            "  -1.1597271e+00 -7.5328064e-01]\n",
            " [ 2.6537970e-01 -9.3219274e-01 -8.8812852e-01 ... -1.8236890e+00\n",
            "  -1.1500872e+00  1.1130560e+01]]\n",
            "sec:  [[3.]\n",
            " [5.]\n",
            " [1.]\n",
            " ...\n",
            " [9.]\n",
            " [0.]\n",
            " [5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '9-Section Unloaded state Dataset (Section Classification)'"
      ],
      "metadata": {
        "id": "n0LPcqUk43Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_Cla = data_for_sec[sheets_sec[4]]\n",
        "dataset_sec_Cla = MyBaseDataset_for_sec_Cla(sheet_sec_Cla.values)\n",
        "dataloader_sec_Cla = DataLoader(dataset=dataset_sec_Cla,batch_size=len(dataset_sec_Cla) , shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "for i, (inputs, sec) in enumerate(dataloader_sec_Cla):\n",
        "  pass\n",
        "\n",
        "inputs = inputs.numpy()\n",
        "sec = sec.numpy()\n",
        "\n",
        "\n",
        "B_train_Cla_9_UL, B_test_Cla_9_UL, sec_train_9_UL, sec_test_9_UL = train_test_split(inputs, sec, random_state=1)\n",
        "print(\"B_train: \", B_train_Cla_9_UL)\n",
        "print(\"sec: \", sec_train_9_UL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eafa8bc-453f-4162-cd5e-ee50f1154dbb",
        "id": "7kh9gZp243Ah"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train:  [[-9.1353226e-01 -2.5013217e-01 -1.7800174e+00 ...  1.3169779e+00\n",
            "  -1.0890472e+00 -2.1314797e+00]\n",
            " [ 4.5469207e-01 -1.1110662e+00  1.8307078e-01 ... -1.8811239e+00\n",
            "   8.0819678e-01 -1.2678894e+00]\n",
            " [-9.7254544e-01  9.0658973e-04  4.7134614e+00 ... -7.9544818e-01\n",
            "  -2.1301482e+00  3.2062552e+00]\n",
            " ...\n",
            " [ 1.2574178e-01 -6.5627947e-02 -1.0174589e+00 ... -8.1967074e-01\n",
            "   8.2012278e-01 -1.0581492e+00]\n",
            " [ 2.7454535e-02  9.0658973e-04  7.1346146e-01 ...  1.2045518e+00\n",
            "  -1.1301482e+00  2.0625511e-01]\n",
            " [ 2.0274546e+00  9.0658973e-04 -2.2865386e+00 ... -7.9544818e-01\n",
            "  -1.1301482e+00  2.0625511e-01]]\n",
            "sec:  [[0.]\n",
            " [0.]\n",
            " [8.]\n",
            " ...\n",
            " [2.]\n",
            " [0.]\n",
            " [3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making 'Summation Load & Unload state Dataset (Section Classification)'"
      ],
      "metadata": {
        "id": "WtENyX7-D8hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sec_train_9_L=sec_train_9_L*111\n",
        "sec_test_9_L=sec_test_9_L*111\n",
        "sec_train_9_UL=sec_train_9_UL*111\n",
        "sec_test_9_UL=sec_test_9_UL*111"
      ],
      "metadata": {
        "id": "aJa8VdWKHi-0"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B_train_F_load = np.concatenate((B_train_Cla_81_L, B_train_Cla_9_L), axis=0)\n",
        "B_test_F_load = np.concatenate((B_test_Cla_81_L, B_test_Cla_9_L), axis=0)\n",
        "F_train_load = np.concatenate((sec_train_81_L, sec_train_9_L), axis=0)\n",
        "F_test_load = np.concatenate((sec_test_81_L, sec_test_9_L), axis=0)\n",
        "\n",
        "B_train_F_unload = np.concatenate((B_train_Cla_81_UL, B_train_Cla_9_UL), axis=0)\n",
        "B_test_F_unload = np.concatenate((B_test_Cla_81_UL, B_test_Cla_9_UL), axis=0)\n",
        "F_train_unload = np.concatenate((sec_train_81_UL, sec_train_9_UL), axis=0)\n",
        "F_test_unload = np.concatenate((sec_test_81_UL, sec_test_9_UL), axis=0)\n",
        "\n",
        "\n",
        "train_beforesuffle_load = np.concatenate((B_train_F_load, F_train_load), axis=1)\n",
        "test_beforesuffle_load = np.concatenate((B_test_F_load, F_test_load), axis=1)\n",
        "\n",
        "train_beforesuffle_unload = np.concatenate((B_train_F_unload, F_train_unload), axis=1)\n",
        "test_beforesuffle_unload = np.concatenate((B_test_F_unload, F_test_unload), axis=1)\n",
        "\n",
        "print(\" train_beforesuffle_load : \", train_beforesuffle_load)\n",
        "print(\" len : \", len(train_beforesuffle_load))\n",
        "print(\" test_beforesuffle_load : \", test_beforesuffle_load)\n",
        "\n",
        "print(\" train_beforesuffle_unload : \", train_beforesuffle_unload)\n",
        "print(\" shape : \", train_beforesuffle_unload.shape)\n",
        "print(\" test_beforesuffle_unload : \", test_beforesuffle_unload)\n",
        "\n",
        "np.random.shuffle(train_beforesuffle_load)\n",
        "np.random.shuffle(test_beforesuffle_load)\n",
        "\n",
        "np.random.shuffle(train_beforesuffle_unload)\n",
        "np.random.shuffle(test_beforesuffle_unload)\n",
        "\n",
        "\n",
        "B_train_sec_load = train_beforesuffle_load[:,:12]\n",
        "B_test_sec_load = test_beforesuffle_load[:,:12]\n",
        "sec_train_load = train_beforesuffle_load[:,12]\n",
        "sec_train_load = sec_train_load.reshape(len(F_train_load),1)\n",
        "sec_test_load = test_beforesuffle_load[:,12]\n",
        "sec_test_load = sec_test_load.reshape(len(F_test_load),1)\n",
        "\n",
        "B_train_sec_unload = train_beforesuffle_unload[:,:12]\n",
        "B_test_sec_unload = test_beforesuffle_unload[:,:12]\n",
        "sec_train_unload = train_beforesuffle_unload[:,12]\n",
        "sec_train_unload = sec_train_unload.reshape(len(F_train_unload),1)\n",
        "sec_test_unload = test_beforesuffle_unload[:,12]\n",
        "sec_test_unload = sec_test_unload.reshape(len(F_test_unload),1)\n",
        "\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
        "\n",
        "print(\"B_train_sec_load: \", B_train_sec_load)\n",
        "print(\"sec_load: \", sec_train_load)\n",
        "\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
        "\n",
        "print(\"B_train_sec_unload: \", B_train_sec_unload)\n",
        "print(\"sec_unload: \", sec_train_unload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCcYfFp6ELef",
        "outputId": "c477ddf9-56a3-4a01-c462-74e5244448d2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " train_beforesuffle_load :  [[ 3.6680916e-01  1.1880637e+00 -7.3324065e+00 ... -4.0426331e+01\n",
            "  -3.1685595e+01  2.4000000e+01]\n",
            " [ 2.8050548e-01 -1.5635498e+00  1.3294873e+00 ...  1.6788399e+00\n",
            "  -5.6491437e+00  8.1000000e+01]\n",
            " [-7.1949452e-01  4.3645024e-01  1.3294873e+00 ... -3.2116014e-01\n",
            "  -6.4914382e-01  0.0000000e+00]\n",
            " ...\n",
            " [ 2.6537970e-01 -9.3219274e-01  1.6111872e+01 ... -1.1500872e+00\n",
            "   1.1305597e+00  9.9900000e+02]\n",
            " [ 1.9760938e+00 -2.1768957e+01  1.4856535e+02 ... -1.1597271e+00\n",
            "  -7.5328064e-01  0.0000000e+00]\n",
            " [ 2.6537970e-01 -9.3219274e-01 -8.8812852e-01 ... -1.1500872e+00\n",
            "   1.1130560e+01  5.5500000e+02]]\n",
            " len :  43294\n",
            " test_beforesuffle_load :  [[-2.4941726e-01 -4.1175538e-01 -8.6320323e-01 ...  4.1682780e-01\n",
            "  -7.9467006e+00  8.0000000e+00]\n",
            " [-1.5460275e+00 -3.7734982e-01  5.3528309e-01 ... -7.5242430e-01\n",
            "  -2.2639725e+00  7.3000000e+01]\n",
            " [ 2.3668091e+00  6.1880636e+00 -6.7332405e+01 ... -4.8426331e+01\n",
            "   9.1314407e+01  4.8000000e+01]\n",
            " ...\n",
            " [ 2.6537970e-01  6.7807287e-02 -3.8881285e+00 ...  1.8499128e+00\n",
            "   1.3055968e-01  3.3300000e+02]\n",
            " [-1.7346203e+00  6.7807287e-02  1.8111872e+01 ... -1.1500872e+00\n",
            "   1.1305597e+00  8.8800000e+02]\n",
            " [ 2.7454535e-02  1.0009066e+00 -3.2865386e+00 ...  8.6985183e-01\n",
            "  -7.9374486e-01  3.3300000e+02]]\n",
            " train_beforesuffle_unload :  [[ 3.3668091e+00  3.1880636e+00 -3.9332405e+01 ... -3.8426331e+01\n",
            "  -6.8685593e+01  5.9000000e+01]\n",
            " [ 4.3668094e+00  5.1880636e+00 -6.8332405e+01 ... -4.2426331e+01\n",
            "  -2.3685595e+01  5.2000000e+01]\n",
            " [ 7.5058275e-01  5.8824462e-01  1.1367968e+00 ...  4.1682780e-01\n",
            "  -1.9467003e+00  1.0000000e+00]\n",
            " ...\n",
            " [ 1.2574178e-01 -6.5627947e-02 -1.0174589e+00 ...  8.2012278e-01\n",
            "  -1.0581492e+00  2.2200000e+02]\n",
            " [ 2.7454535e-02  9.0658973e-04  7.1346146e-01 ... -1.1301482e+00\n",
            "   2.0625511e-01  0.0000000e+00]\n",
            " [ 2.0274546e+00  9.0658973e-04 -2.2865386e+00 ... -1.1301482e+00\n",
            "   2.0625511e-01  3.3300000e+02]]\n",
            " shape :  (42678, 13)\n",
            " test_beforesuffle_unload :  [[ 1.3668091e+00  1.1880637e+00 -1.1332406e+01 ... -4.2426331e+01\n",
            "  -1.9685595e+01  3.3000000e+01]\n",
            " [-5.6331906e+00 -4.8119364e+00  9.1667595e+01 ... -4.1426331e+01\n",
            "  -9.6855955e+00  4.4000000e+01]\n",
            " [-2.4941726e-01  5.8824462e-01  1.3679679e-01 ... -5.8317220e-01\n",
            "  -4.9467006e+00  7.0000000e+00]\n",
            " ...\n",
            " [-7.4614978e-01 -2.1006364e-02 -1.7666115e+00 ... -1.1146252e+00\n",
            "  -1.4997162e+00  9.9900000e+02]\n",
            " [ 1.2653797e+00  6.7807287e-02 -1.4888128e+01 ...  1.8499128e+00\n",
            "  -3.1869440e+01  5.5500000e+02]\n",
            " [ 2.6537970e-01  1.0678073e+00  1.1187147e-01 ...  8.4991282e-01\n",
            "   1.3055968e-01  0.0000000e+00]]\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "B_train_sec_load:  [[ -1.2494173   -0.41175538   1.1367968  ...   1.917181     3.4168277\n",
            "  -31.946701  ]\n",
            " [  0.36680916   3.1880636  -38.332405   ... -32.67036    -40.42633\n",
            "  -64.68559   ]\n",
            " [ -0.73462033  -1.9321927   32.11187    ...  -0.823689     0.8499128\n",
            "    4.1305594 ]\n",
            " ...\n",
            " [  0.36680916   0.1880637  -12.332406   ... -37.67036    -42.42633\n",
            "   -9.6855955 ]\n",
            " [ -0.6331908   -0.8119363    2.6675937  ... -34.67036    -41.42633\n",
            "  -18.685595  ]\n",
            " [ -0.54530793  -0.11106624   0.18307078 ...  -1.8811239    1.8081968\n",
            "   -1.2678894 ]]\n",
            "sec_load:  [[  1.]\n",
            " [ 69.]\n",
            " [666.]\n",
            " ...\n",
            " [ 20.]\n",
            " [ 34.]\n",
            " [111.]]\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "B_train_sec_unload:  [[ 4.5397249e-01  6.2265015e-01 -2.4647169e+00 ...  9.5900494e-01\n",
            "   1.2475756e+00 -1.7263973e+01]\n",
            " [ 1.3668091e+00  3.1880636e+00 -3.9332405e+01 ... -3.9670361e+01\n",
            "  -4.6426331e+01  9.2314407e+01]\n",
            " [-5.4602748e-01  6.2265015e-01 -4.6471691e-01 ... -1.0409951e+00\n",
            "   1.2475756e+00 -1.2639725e+00]\n",
            " ...\n",
            " [ 8.6467773e-02 -1.2501322e+00  2.1998256e-01 ...  1.3169779e+00\n",
            "   1.9109528e+00 -1.3147983e-01]\n",
            " [-7.3462033e-01 -1.9321927e+00  1.8111872e+01 ...  1.1763110e+00\n",
            "  -1.1500872e+00 -2.8694403e+00]\n",
            " [ 3.3668091e+00  5.1880636e+00 -6.9332405e+01 ... -3.2670361e+01\n",
            "  -4.0426331e+01 -4.9685596e+01]]\n",
            "sec_unload:  [[ 74.]\n",
            " [ 55.]\n",
            " [  0.]\n",
            " ...\n",
            " [  0.]\n",
            " [888.]\n",
            " [ 50.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Learning (Section Classification)\n",
        "you can modify this code to make a model that you need"
      ],
      "metadata": {
        "id": "b-4Nvmu05jk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "# size of each layer can be modified to find best fit\n",
        "model = MLPClassifier(hidden_layer_sizes=(256, 256, 64, 256), activation='relu', solver='adam', \\\n",
        "                     learning_rate='constant', learning_rate_init=0.0005, max_iter=2000, \\\n",
        "                     batch_size='auto', shuffle=True, random_state=100)\n",
        "\n",
        "model.fit(B_train_sec_unload, sec_train_unload)\n",
        "\n",
        "print(f\"Score of Section accuracy of model  : {float(model.score(B_test_sec_unload, sec_test_unload))*100:.3f}% \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz95C9VT5sxc",
        "outputId": "b129f3d8-6443-433b-ebe3-b87966eaec53"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score of Section accuracy of model  : 91.481% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Force regression model"
      ],
      "metadata": {
        "id": "cccZuko11Xb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Google drive and call the Dataset (Force regression)"
      ],
      "metadata": {
        "id": "c5fZwhDYtn1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIcPWtAo-JAn",
        "outputId": "232f1452-d800-45bb-e531-91e49c631208"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class MyBaseDataset_for_F(Dataset):\n",
        "  # reading sensor data in order of \"Bx1\tBy1\tBz1\tBx2\tBy2\tBz2\tBx3\tBy3\tBz3\tBx4\tBy4\tBz4\tF\ttime\tsection\"\n",
        "  def __init__(self, data_input):\n",
        "    data_input = torch.tensor(data_input).float()\n",
        "    L = data_input[:,14].view([-1,1])\n",
        "    xyzL = torch.cat([data_input[:,:12],L], dim=1)\n",
        "    self.xyz_data_and_label = xyzL\n",
        "    self.force = data_input[:, [12]]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.xyz_data_and_label[index], self.force[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.xyz_data_and_label.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "data_for_sec = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/2023 Advanced/Sensor_data.xlsx', sheet_name=None)\n",
        "sheets_sec = list(data_for_sec.keys())"
      ],
      "metadata": {
        "id": "hqxBOu541yVR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '81-Section Load state Dataset (Force regression)'"
      ],
      "metadata": {
        "id": "QT7Ml1sjvMZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_81_load = data_for_sec[sheets_sec[0]]\n",
        "dataset_sec_81_load = MyBaseDataset_for_F(sheet_sec_81_load.values)\n",
        "dataloader_sec_81_load = DataLoader(dataset=dataset_sec_81_load,batch_size=len(dataset_sec_81_load) , shuffle=True, num_workers=2)\n",
        "\n",
        "for i, (inputs_81_load, F_81_load) in enumerate(dataloader_sec_81_load):\n",
        "  pass\n",
        "\n",
        "inputs_81_load = inputs_81_load.numpy()\n",
        "F_81_load = F_81_load.numpy()\n",
        "\n",
        "B_train_81_load, B_test_81_load, F_train_81_load, F_test_81_load = train_test_split(inputs_81_load, F_81_load, random_state=1)\n",
        "print(\"B_train_81_load: \", B_train_81_load)\n",
        "print(\"F_train_81_load: \", F_train_81_load)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuZedUK2vQ7G",
        "outputId": "6b643e42-53e5-4774-fd4a-fed2666d1089"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train_81_load:  [[  0.36680916   2.1880636  -29.332407   ... -38.42633    -61.685596\n",
            "   70.        ]\n",
            " [ -0.6331908    1.1880637  -19.332407   ... -37.42633    -86.68559\n",
            "   72.        ]\n",
            " [ -1.2494173    0.5882446   -0.8632032  ...   0.4168278    1.0532997\n",
            "   12.        ]\n",
            " ...\n",
            " [ -0.24941726  -0.41175538  -0.8632032  ...   1.4168278   -7.9467006\n",
            "   13.        ]\n",
            " [  0.36680916   2.1880636  -25.332407   ... -40.42633    -63.685596\n",
            "   70.        ]\n",
            " [  3.3668091    4.1880636  -67.332405   ... -38.42633    -80.68559\n",
            "   66.        ]]\n",
            "F_train_81_load:  [[0.33]\n",
            " [2.23]\n",
            " [0.28]\n",
            " ...\n",
            " [1.37]\n",
            " [0.89]\n",
            " [0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '81-Section Unload state Dataset (Force regression)'"
      ],
      "metadata": {
        "id": "Hs4a-zyXwudB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_81_unload = data_for_sec[sheets_sec[1]]\n",
        "dataset_sec_81_unload = MyBaseDataset_for_F(sheet_sec_81_unload.values)\n",
        "dataloader_sec_81_unload = DataLoader(dataset=dataset_sec_81_unload,batch_size=len(dataset_sec_81_unload) , shuffle=True, num_workers=2)\n",
        "\n",
        "for i, (inputs_81_unload, F_81_unload) in enumerate(dataloader_sec_81_unload):\n",
        "  pass\n",
        "\n",
        "inputs_81_unload = inputs_81_unload.numpy()\n",
        "F_81_unload = F_81_unload.numpy()\n",
        "\n",
        "B_train_81_unload, B_test_81_unload, F_train_81_unload, F_test_81_unload = train_test_split(inputs_81_unload, F_81_unload, random_state=1)\n",
        "print(\"B_train_81_unload: \", B_train_81_unload)\n",
        "print(\"F_train_81_unload: \", F_train_81_unload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C71V7b52w5bM",
        "outputId": "daca87e7-6522-4441-d567-939088fd04ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train_81_unload:  [[  0.75058275   0.5882446    0.13679679 ...  -0.5831722   -3.9467003\n",
            "   11.        ]\n",
            " [  2.3668091    1.1880637  -28.332407   ... -44.42633     28.314405\n",
            "   28.        ]\n",
            " [  1.4539725    1.6226501  -12.464717   ...   1.2475756  -34.263973\n",
            "   79.        ]\n",
            " ...\n",
            " [  0.36680916   0.1880637  -10.332406   ... -41.42633     18.314405\n",
            "   20.        ]\n",
            " [  2.3668091    2.1880636  -29.332407   ... -48.42633     93.31441\n",
            "   29.        ]\n",
            " [  0.4539725    0.62265015  -6.464717   ...  -0.7524243  -13.263972\n",
            "   76.        ]]\n",
            "F_train_81_unload:  [[1.1 ]\n",
            " [0.  ]\n",
            " [2.48]\n",
            " ...\n",
            " [1.49]\n",
            " [0.56]\n",
            " [0.61]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '9-Section Load state Dataset (Force regression)'\n"
      ],
      "metadata": {
        "id": "8Dml1GE5wyPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_9_load = data_for_sec[sheets_sec[3]]\n",
        "dataset_sec_9_load = MyBaseDataset_for_F(sheet_sec_9_load.values)\n",
        "dataloader_sec_9_load = DataLoader(dataset=dataset_sec_9_load,batch_size=len(dataset_sec_9_load) , shuffle=True, num_workers=2)\n",
        "\n",
        "for i, (inputs_9_load, F_9_load) in enumerate(dataloader_sec_9_load):\n",
        "  pass\n",
        "\n",
        "inputs_9_load = inputs_9_load.numpy()\n",
        "F_9_load = F_9_load.numpy()\n",
        "\n",
        "B_train_9_load, B_test_9_load, F_train_9_load, F_test_9_load = train_test_split(inputs_9_load, F_9_load, random_state=1)\n",
        "print(\"B_train_9_load: \", B_train_9_load)\n",
        "print(\"F_train_9_load: \", F_train_9_load)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTK1Xjh-xDHC",
        "outputId": "7cbc7767-234b-441d-d26b-bad6e5e43a35"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train_9_load:  [[ 9.7609371e-01 -2.1768957e+01  1.4856535e+02 ...  8.4027290e-01\n",
            "   1.2467194e+00  0.0000000e+00]\n",
            " [-9.1353226e-01 -2.5013217e-01 -7.8001744e-01 ...  9.1095287e-01\n",
            "  -6.1314797e+00  1.0000000e+00]\n",
            " [ 1.2574178e-01  9.3437207e-01 -4.0174589e+00 ... -1.1798772e+00\n",
            "  -1.0058149e+01  5.0000000e+00]\n",
            " ...\n",
            " [-9.7254544e-01 -9.9909341e-01 -3.2865386e+00 ...  8.6985183e-01\n",
            "   2.0625511e-01  3.0000000e+00]\n",
            " [ 1.2574178e-01 -6.5627947e-02 -1.0174589e+00 ... -1.1798772e+00\n",
            "  -1.0581492e+00  0.0000000e+00]\n",
            " [-9.7254544e-01  9.0658973e-04  5.7134614e+00 ... -1.1301482e+00\n",
            "   2.2062552e+00  7.0000000e+00]]\n",
            "F_train_9_load:  [[ 0.  ]\n",
            " [ 0.7 ]\n",
            " [ 0.98]\n",
            " ...\n",
            " [ 0.  ]\n",
            " [ 0.  ]\n",
            " [-0.01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making '9-Section Unload state Dataset (Force regression)'"
      ],
      "metadata": {
        "id": "UQDVWANjw9gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_sec_9_unload = data_for_sec[sheets_sec[4]]\n",
        "dataset_sec_9_unload = MyBaseDataset_for_F(sheet_sec_9_unload.values)\n",
        "dataloader_sec_9_unload = DataLoader(dataset=dataset_sec_9_unload,batch_size=len(dataset_sec_9_unload) , shuffle=True, num_workers=2) # numworkers     . 2 \n",
        "\n",
        "for i, (inputs_9_unload, F_9_unload) in enumerate(dataloader_sec_9_unload):\n",
        "  pass\n",
        "\n",
        "inputs_9_unload = inputs_9_unload.numpy()\n",
        "F_9_unload = F_9_unload.numpy()\n",
        "\n",
        "B_train_9_unload, B_test_9_unload, F_train_9_unload, F_test_9_unload = train_test_split(inputs_9_unload, F_9_unload, random_state=1)\n",
        "print(\"B_train_9_unload: \", B_train_9_unload)\n",
        "print(\"F_train_9_unload: \", F_train_9_unload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBGHB4Q2xOIv",
        "outputId": "e324ed0d-a853-4a78-c903-dbc579182524"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_train_9_unload:  [[-3.8742583e+00 -3.0656281e+00  5.4982540e+01 ...  8.2012278e-01\n",
            "   2.9418507e+00  6.0000000e+00]\n",
            " [-9.1353226e-01 -2.5013217e-01  2.1998256e-01 ... -1.0890472e+00\n",
            "  -1.1314799e+00  4.0000000e+00]\n",
            " [-8.7425822e-01 -6.5627947e-02  5.9825411e+00 ...  8.2012278e-01\n",
            "  -2.0581493e+00  8.0000000e+00]\n",
            " ...\n",
            " [-1.8742582e+00 -6.5627947e-02  2.0982540e+01 ...  8.2012278e-01\n",
            "   2.9418507e+00  6.0000000e+00]\n",
            " [-1.8742582e+00 -1.0656279e+00  2.1982540e+01 ... -1.1798772e+00\n",
            "   4.9418507e+00  6.0000000e+00]\n",
            " [ 9.7609371e-01 -2.1768957e+01  1.5156535e+02 ... -1.1597271e+00\n",
            "   1.2467194e+00  7.0000000e+00]]\n",
            "F_train_9_unload:  [[ 0.92]\n",
            " [ 0.  ]\n",
            " [ 0.78]\n",
            " ...\n",
            " [-0.01]\n",
            " [ 0.  ]\n",
            " [ 0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making 'Summation Load & Unload state Dataset (Force regression)'"
      ],
      "metadata": {
        "id": "pN_FpSzExUPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_train_9_load[:,12]=B_train_9_load[:,12]*111\n",
        "B_test_9_load[:,12]=B_test_9_load[:,12]*111\n",
        "B_train_9_unload[:,12]=B_train_9_unload[:,12]*111\n",
        "B_test_9_unload[:,12]=B_test_9_unload[:,12]*111\n",
        "print(B_train_9_load[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04O0wFa8-eoZ",
        "outputId": "be2d710e-c188-42ad-cb40-9b01aa985e3c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-9.1353226e-01 -2.5013217e-01 -7.8001744e-01  2.4228683e-02\n",
            "  1.2242869e+00  6.8553281e+00  2.7645794e-01 -1.2477312e+00\n",
            "  1.1645184e+00  1.3169779e+00  9.1095287e-01 -6.1314797e+00\n",
            "  1.1100000e+02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B_train_F_load = np.concatenate((B_train_81_load, B_train_9_load), axis=0)\n",
        "B_test_F_load = np.concatenate((B_test_81_load, B_test_9_load), axis=0)\n",
        "F_train_load = np.concatenate((F_train_81_load, F_train_9_load), axis=0)\n",
        "F_test_load = np.concatenate((F_test_81_load, F_test_9_load), axis=0)\n",
        "\n",
        "B_train_F_unload = np.concatenate((B_train_81_unload, B_train_9_unload), axis=0)\n",
        "B_test_F_unload = np.concatenate((B_test_81_unload, B_test_9_unload), axis=0)\n",
        "F_train_unload = np.concatenate((F_train_81_unload, F_train_9_unload), axis=0)\n",
        "F_test_unload = np.concatenate((F_test_81_unload, F_test_9_unload), axis=0)\n",
        "\n",
        "\n",
        "train_beforesuffle_load = np.concatenate((B_train_F_load, F_train_load), axis=1)\n",
        "test_beforesuffle_load = np.concatenate((B_test_F_load, F_test_load), axis=1)\n",
        "\n",
        "train_beforesuffle_unload = np.concatenate((B_train_F_unload, F_train_unload), axis=1)\n",
        "test_beforesuffle_unload = np.concatenate((B_test_F_unload, F_test_unload), axis=1)\n",
        "\n",
        "print(\" train_beforesuffle_load : \", train_beforesuffle_load)\n",
        "print(\" len : \", len(train_beforesuffle_load))\n",
        "print(\" test_beforesuffle_load : \", test_beforesuffle_load)\n",
        "\n",
        "print(\" train_beforesuffle_unload : \", train_beforesuffle_unload)\n",
        "print(\" shape : \", train_beforesuffle_unload.shape)\n",
        "print(\" test_beforesuffle_unload : \", test_beforesuffle_unload)\n",
        "\n",
        "np.random.shuffle(train_beforesuffle_load)\n",
        "np.random.shuffle(test_beforesuffle_load)\n",
        "\n",
        "np.random.shuffle(train_beforesuffle_unload)\n",
        "np.random.shuffle(test_beforesuffle_unload)\n",
        "\n",
        "\n",
        "B_train_F_load = train_beforesuffle_load[:,:13]\n",
        "B_test_F_load = test_beforesuffle_load[:,:13]\n",
        "F_train_load = train_beforesuffle_load[:,13]\n",
        "F_train_load = F_train_load.reshape(len(F_train_load),1)\n",
        "F_test_load = test_beforesuffle_load[:,13]\n",
        "F_test_load = F_test_load.reshape(len(F_test_load),1)\n",
        "\n",
        "B_train_F_unload = train_beforesuffle_unload[:,:13]\n",
        "B_test_F_unload = test_beforesuffle_unload[:,:13]\n",
        "F_train_unload = train_beforesuffle_unload[:,13]\n",
        "F_train_unload = F_train_unload.reshape(len(F_train_unload),1)\n",
        "F_test_unload = test_beforesuffle_unload[:,13]\n",
        "F_test_unload = F_test_unload.reshape(len(F_test_unload),1)\n",
        "\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
        "\n",
        "print(\"B_train_F_load: \", B_train_F_load)\n",
        "print(\"F_load: \", F_train_load)\n",
        "\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
        "\n",
        "print(\"B_train_F_unload: \", B_train_F_unload)\n",
        "print(\"F_unload: \", F_train_unload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIbuKjACxbEb",
        "outputId": "e8e038d1-4e8e-4ffe-f105-e0de2a36abdf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " train_beforesuffle_load :  [[ 3.6680916e-01  2.1880636e+00 -2.9332407e+01 ... -6.1685596e+01\n",
            "   7.0000000e+01  3.3000001e-01]\n",
            " [-6.3319081e-01  1.1880637e+00 -1.9332407e+01 ... -8.6685593e+01\n",
            "   7.2000000e+01  2.2300000e+00]\n",
            " [-1.2494173e+00  5.8824462e-01 -8.6320323e-01 ...  1.0532997e+00\n",
            "   1.2000000e+01  2.8000000e-01]\n",
            " ...\n",
            " [-9.7254544e-01 -9.9909341e-01 -3.2865386e+00 ...  2.0625511e-01\n",
            "   3.3300000e+02  0.0000000e+00]\n",
            " [ 1.2574178e-01 -6.5627947e-02 -1.0174589e+00 ... -1.0581492e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [-9.7254544e-01  9.0658973e-04  5.7134614e+00 ...  2.2062552e+00\n",
            "   7.7700000e+02 -9.9999998e-03]]\n",
            " len :  43294\n",
            " test_beforesuffle_load :  [[ 1.3668091e+00  2.1880636e+00 -3.4332405e+01 ... -1.9685595e+01\n",
            "   4.2000000e+01  2.4600000e+00]\n",
            " [-5.4602748e-01 -3.7734982e-01 -1.4647169e+00 ... -8.2639723e+00\n",
            "   7.3000000e+01  7.4000001e-01]\n",
            " [ 3.3668091e+00  4.1880636e+00 -5.9332405e+01 ... -8.4685593e+01\n",
            "   6.8000000e+01  3.0999999e+00]\n",
            " ...\n",
            " [ 2.7454535e-02  1.0009066e+00 -6.2865386e+00 ...  2.0625511e-01\n",
            "   3.3300000e+02  1.4200000e+00]\n",
            " [-7.4614978e-01 -1.0210063e+00  2.3338854e-01 ... -1.4997162e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [-1.7346203e+00 -1.9321927e+00  2.2111872e+01 ... -1.8694403e+00\n",
            "   7.7700000e+02  9.5999998e-01]]\n",
            " train_beforesuffle_unload :  [[ 7.5058275e-01  5.8824462e-01  1.3679679e-01 ... -3.9467003e+00\n",
            "   1.1000000e+01  1.1000000e+00]\n",
            " [ 2.3668091e+00  1.1880637e+00 -2.8332407e+01 ...  2.8314405e+01\n",
            "   2.8000000e+01  0.0000000e+00]\n",
            " [ 1.4539725e+00  1.6226501e+00 -1.2464717e+01 ... -3.4263973e+01\n",
            "   7.9000000e+01  2.4800000e+00]\n",
            " ...\n",
            " [-1.8742582e+00 -6.5627947e-02  2.0982540e+01 ...  2.9418507e+00\n",
            "   6.6600000e+02 -9.9999998e-03]\n",
            " [-1.8742582e+00 -1.0656279e+00  2.1982540e+01 ...  4.9418507e+00\n",
            "   6.6600000e+02  0.0000000e+00]\n",
            " [ 9.7609371e-01 -2.1768957e+01  1.5156535e+02 ...  1.2467194e+00\n",
            "   7.7700000e+02  0.0000000e+00]]\n",
            " shape :  (42678, 14)\n",
            " test_beforesuffle_unload :  [[ 3.3668091e+00  2.1880636e+00 -5.4332405e+01 ...  7.6314407e+01\n",
            "   3.9000000e+01  2.5799999e+00]\n",
            " [-3.6331909e+00  1.8806370e-01  2.2667593e+01 ... -7.6855950e+00\n",
            "   4.5000000e+01  9.9999998e-03]\n",
            " [ 3.3668091e+00  3.1880636e+00 -6.7332405e+01 ... -5.4685596e+01\n",
            "   6.5000000e+01  5.6000000e-01]\n",
            " ...\n",
            " [ 2.6537970e-01 -9.3219274e-01  1.1118715e+00 ...  1.3055968e-01\n",
            "   3.3300000e+02  1.6300000e+00]\n",
            " [ 1.9760938e+00 -2.1768957e+01  1.4856535e+02 ... -7.5328064e-01\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [ 2.5385022e-01  1.9789937e+00 -1.7666115e+00 ... -3.4997160e+00\n",
            "   1.1100000e+02  5.6000000e-01]]\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "B_train_F_load:  [[-3.97254539e+00 -5.99909353e+00  7.97134628e+01 ... -1.13014817e+00\n",
            "   6.20625496e+00  6.66000000e+02]\n",
            " [-7.63319063e+00 -5.81193638e+00  1.15667595e+02 ... -4.04263306e+01\n",
            "  -3.06855946e+01  5.30000000e+01]\n",
            " [ 2.36680913e+00  2.18806362e+00 -4.93324051e+01 ... -4.44263306e+01\n",
            "   4.13144035e+01  5.70000000e+01]\n",
            " ...\n",
            " [ 1.36680913e+00  1.88063696e-01 -6.33240652e+00 ... -4.24263306e+01\n",
            "   1.03144045e+01  1.90000000e+01]\n",
            " [-2.49417260e-01 -4.11755383e-01  1.36796787e-01 ...  1.41682780e+00\n",
            "  -9.46700394e-01  0.00000000e+00]\n",
            " [ 1.36680913e+00  1.88063696e-01 -5.33240652e+00 ... -4.04263306e+01\n",
            "  -3.36855965e+01  2.50000000e+01]]\n",
            "F_load:  [[1.09]\n",
            " [1.28]\n",
            " [2.31]\n",
            " ...\n",
            " [0.05]\n",
            " [0.  ]\n",
            " [1.11]]\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "B_train_F_unload:  [[ 4.5469207e-01  1.8889338e+00 -1.8169292e+00 ...  8.0819678e-01\n",
            "  -1.2678894e+00  9.9900000e+02]\n",
            " [ 1.3668091e+00  2.1880636e+00 -1.4332406e+01 ... -4.1426331e+01\n",
            "  -1.9685595e+01  3.4000000e+01]\n",
            " [ 3.6680916e-01  1.8806370e-01  6.6759372e-01 ... -4.2426331e+01\n",
            "  -8.6855955e+00  1.6000000e+01]\n",
            " ...\n",
            " [-9.7254544e-01  9.0658973e-04  5.7134614e+00 ...  1.8698518e+00\n",
            "   2.2062552e+00  8.8800000e+02]\n",
            " [-2.4941726e-01  5.8824462e-01 -8.6320323e-01 ... -5.8317220e-01\n",
            "  -4.9467006e+00  9.0000000e+00]\n",
            " [-2.4941726e-01  5.8824462e-01  1.3679679e-01 ...  4.1682780e-01\n",
            "   1.0532997e+00  5.0000000e+00]]\n",
            "F_unload:  [[ 1.08]\n",
            " [ 0.06]\n",
            " [ 0.45]\n",
            " ...\n",
            " [-0.01]\n",
            " [ 0.  ]\n",
            " [-0.02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Learning (Force measuring)\n",
        "you can modify this code to make a model that you need"
      ],
      "metadata": {
        "id": "d6yesm7fxjSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# size of each layer can be modified to find best fit\n",
        "model_load = MLPRegressor(hidden_layer_sizes=(230, 230, 30, 230), activation='relu', solver='adam', \\\n",
        "                     learning_rate='constant', learning_rate_init=0.0005, max_iter=3000, \\\n",
        "                     batch_size='auto', shuffle=True, random_state=100)\n",
        "\n",
        "# For making a Force model (loaded) with Summation dataset :\n",
        "model_load.fit(B_train_F_load, F_train_load)\n",
        "\n",
        "\n",
        "print(f\"Score of Force accuracy of loaded model  : {float(model_load.score(B_test_F_load, F_test_load))*100:.3f}% \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axqXEycPx6jE",
        "outputId": "ec2c8848-4a06-4ca6-e1b9-d47c039e415d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score of Force accuracy of loaded model  : 94.540% \n"
          ]
        }
      ]
    }
  ]
}